{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7: Teaching Machines to See Better\n",
    "\n",
    "## 1️⃣ Chapter Overview\n",
    "\n",
    "In the previous chapter, we built an InceptionNet v1 classifier. While powerful, complex models often suffer from **overfitting**—memorizing the training data rather than generalizing to new examples. \n",
    "\n",
    "This chapter focuses on turning a \"good\" model into a \"great\" one. We will explore advanced regularization techniques to prevent overfitting, architect a more efficient custom model called **Minception** (a miniature Inception-ResNet), and leverage the power of **Transfer Learning**. Finally, we will demystify the \"Black Box\" of Deep Learning using **Grad-CAM** to visualize exactly which parts of an image the model is looking at.\n",
    "\n",
    "### Key Concepts:\n",
    "* **Regularization:** Data Augmentation, Dropout, and Early Stopping.\n",
    "* **Advanced Architectures:** Residual Connections (ResNet) and Batch Normalization.\n",
    "* **Transfer Learning:** Fine-tuning pretrained models (e.g., InceptionResNetV2).\n",
    "* **Explainable AI (XAI):** Grad-CAM (Gradient-weighted Class Activation Mapping).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ Theoretical Explanation\n",
    "\n",
    "### 2.1 The Battle Against Overfitting\n",
    "Overfitting occurs when a model learns the *noise* in the training data rather than the *signal*. [cite_start]We use three main weapons to combat this[cite: 26, 27]:\n",
    "\n",
    "1.  **Data Augmentation:** artificially increasing the diversity of the training set by applying random transformations (rotations, zooms, flips). This forces the model to learn features that are invariant to position and orientation.\n",
    "2.  **Dropout:** Randomly \"switching off\" a fraction of neurons during training. [cite_start]This prevents neurons from co-adapting too much (i.e., relying on specific other neurons to fix their mistakes) and forces the network to learn robust, redundant features[cite: 26].\n",
    "3.  [cite_start]**Early Stopping:** Monitoring a metric (like validation loss) and stopping training when it stops improving, preventing the model from spiraling into overfitting in later epochs[cite: 26].\n",
    "\n",
    "### 2.2 Advanced Building Blocks\n",
    "\n",
    "#### Batch Normalization (BN)\n",
    "Deep networks suffer from \"Internal Covariate Shift,\" where the distribution of layer inputs changes constantly during training. BN normalizes the output of a layer (subtracting mean, dividing by standard deviation) before passing it to the next. This stabilizes gradients and allows for higher learning rates.\n",
    "\n",
    "#### Residual Connections (ResNet)\n",
    "As networks get deeper, gradients vanish (become zero), making training impossible. **Residual Connections** introduce a \"shortcut\" or \"skip connection\" that adds the input of a block directly to its output:\n",
    "$$ Output = f(x) + x $$\n",
    [cite_start]"This allows gradients to flow through the network highway unimpeded[cite: 27].\n",
    "\n",
    "### 2.3 Transfer Learning\n",
    "Instead of training from scratch, we take a model trained on a massive dataset (like ImageNet with 1.2M images) and reuse its learned feature extractors. We only retrain the top classification layers. [cite_start]This saves time and computational resources[cite: 27].\n",
    "\n",
    "### 2.4 Grad-CAM (Explainability)\n",
    "Grad-CAM answers the question: *\"Why did the model predict 'Cat'?\"* \n",
    "It computes the gradients of the predicted class score with respect to the feature maps of the last convolutional layer. [cite_start]These gradients indicate which regions of the image were most important for that specific prediction[cite: 27]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ Section 1: Reducing Overfitting\n",
    "\n",
    "We will implement Data Augmentation using `ImageDataGenerator`, add Dropout to a model, and define an Early Stopping callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Data Augmentation\n",
    "# We define a generator that applies random transformations\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,             # Normalization\n",
    "    rotation_range=40,          # Rotate image randomly up to 40 degrees\n",
    "    width_shift_range=0.2,      # Shift width\n",
    "    height_shift_range=0.2,     # Shift height\n",
    "    shear_range=0.2,            # Shear transformation\n",
    "    zoom_range=0.2,             # Zoom in/out\n",
    "    horizontal_flip=True,       # Flip horizontally\n",
    "    fill_mode='nearest'         # How to fill missing pixels after move\n",
    ")\n",
    "\n",
    "# Validation data should NOT be augmented (only rescaled)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# 2. Mock Data Generation (Since we don't have the physical dataset)\n",
    "# We generate random noise images to simulate the flow\n",
    "X_train_mock = np.random.rand(100, 64, 64, 3).astype('float32')\n",
    "y_train_mock = tf.keras.utils.to_categorical(np.random.randint(0, 10, 100), 10)\n",
    "\n",
    "X_val_mock = np.random.rand(20, 64, 64, 3).astype('float32')\n",
    "y_val_mock = tf.keras.utils.to_categorical(np.random.randint(0, 10, 20), 10)\n",
    "\n",
    "# Create flow from numpy (simulating flow_from_directory)\n",
    "train_generator = train_datagen.flow(X_train_mock, y_train_mock, batch_size=32)\n",
    "valid_generator = valid_datagen.flow(X_val_mock, y_val_mock, batch_size=32)\n",
    "\n",
    "# 3. Model with Dropout\n",
    "model_reg = Sequential([\n",
    "    Input(shape=(64, 64, 3)),\n",
    "    Conv2D(32, (3,3), activation='relu'),\n",
    "    MaxPooling2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    \n",
    "    # Dropout Layer\n",
    "    # 0.5 means 50% of the neurons are dropped randomly during training\n",
    "    Dropout(0.5),\n",
    "    \n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model_reg.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "# 4. Early Stopping Callback\n",
    "# Stop training if validation loss doesn't improve for 5 epochs\n",
    "es_callback = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=5, \n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "print(\"Training model with Augmentation, Dropout, and Early Stopping...\")\n",
    "# Note: steps_per_epoch is small here just for demonstration\n",
    "history = model_reg.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=5, \n",
    "    callbacks=[es_callback],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ Section 2: Toward Minimalism - The Minception Model\n",
    "\n",
    "The original Inception model is huge. [cite_start]For smaller datasets (like Tiny ImageNet), we can design a more compact version called **Minception** that incorporates the best modern practices: **Batch Normalization** and **Residual Connections**[cite: 27].\n",
    "\n",
    "We will define three main components:\n",
    "1.  **ConvModule:** A helper block (Conv -> Batch Norm -> Activation).\n",
    "2.  **Inception-ResNet Block:** A simplified Inception block with a residual connection.\n",
    "3.  **Reduction Block:** To reduce spatial dimensions (height/width)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Add, BatchNormalization, Activation, Concatenate, AveragePooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# 1. Helper Function: Conv -> BN -> ReLU\n",
    "# This standardizes the most common pattern in modern CNNs\n",
    "def conv_module(x, filters, kernel_size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, kernel_size, strides=strides, padding=padding)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    if activation:\n",
    "        x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "# 2. Inception-ResNet Block\n",
    "# Combines Inception (parallel paths) with ResNet (skip connection)\n",
    "def inception_resnet_block(x, scale=0.1, activation='relu'):\n",
    "    # Save input for residual connection\n",
    "    shortcut = x\n",
    "    \n",
    "    # Branch 1: 1x1 Conv\n",
    "    b1 = conv_module(x, 32, (1,1))\n",
    "    \n",
    "    # Branch 2: 1x1 -> 3x3\n",
    "    b2 = conv_module(x, 32, (1,1))\n",
    "    b2 = conv_module(b2, 32, (3,3))\n",
    "    \n",
    "    # Branch 3: 1x1 -> 3x3 -> 3x3\n",
    "    b3 = conv_module(x, 32, (1,1))\n",
    "    b3 = conv_module(b3, 48, (3,3))\n",
    "    b3 = conv_module(b3, 64, (3,3))\n",
    "    \n",
    "    # Concatenate branches\n",
    "    merged = Concatenate()([b1, b2, b3])\n",
    "    \n",
    "    # 1x1 Conv to match channel dimension of shortcut\n",
    "    # Assuming input x has 128 channels (just for this block example)\n",
    "    # In a full model, this filter size depends on previous layers\n",
    "    filters_in = x.shape[-1]\n",
    "    merged = conv_module(merged, filters_in, (1,1), activation=False)\n",
    "    \n",
    "    # --- The Residual Connection ---\n",
    "    # Add the input (shortcut) to the processed output (merged)\n",
    "    # We scale the residual branch to stabilize training\n",
    "    out = Add()([shortcut, merged * scale])\n",
    "    \n",
    "    if activation:\n",
    "        out = Activation(activation)(out)\n",
    "    return out\n",
    "\n",
    "# 3. Reduction Block\n",
    "# Used to reduce Height/Width (downsampling)\n",
    "def reduction_block(x):\n",
    "    # Branch 1: Max Pool\n",
    "    b1 = MaxPooling2D((3,3), strides=(2,2), padding='same')(x)\n",
    "    \n",
    "    # Branch 2: Strided Conv\n",
    "    b2 = conv_module(x, 128, (3,3), strides=(2,2))\n",
    "    \n",
    "    # Branch 3: 1x1 -> 3x3 -> Strided 3x3\n",
    "    b3 = conv_module(x, 64, (1,1))\n",
    "    b3 = conv_module(b3, 64, (3,3))\n",
    "    b3 = conv_module(b3, 64, (3,3), strides=(2,2))\n",
    "    \n",
    "    # Concatenate\n",
    "    out = Concatenate()([b1, b2, b3])\n",
    "    return out\n",
    "\n",
    "# 4. Building the Minception Model\n",
    "def build_minception(input_shape, n_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Stem\n",
    "    x = conv_module(inputs, 64, (3,3))\n",
    "    x = conv_module(x, 128, (3,3))\n",
    "    \n",
    "    # Inception-ResNet Blocks\n",
    "    x = inception_resnet_block(x)\n",
    "    x = inception_resnet_block(x)\n",
    "    \n",
    "    # Reduction\n",
    "    x = reduction_block(x)\n",
    "    \n",
    "    # More Blocks\n",
    "    # We use a 1x1 conv to adjust channels to match the reduction block output if needed\n",
    "    # For simplicity in this demo, we assume channel compatibility or insert a projection\n",
    "    x = conv_module(x, 128, (1,1)) # Projection to reduce channels for next blocks\n",
    "    x = inception_resnet_block(x)\n",
    "    \n",
    "    # Classifier Head\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(n_classes, activation='softmax')(x)\n",
    "    \n",
    "    return Model(inputs, outputs, name='Minception')\n",
    "\n",
    "minception = build_minception((64, 64, 3), 10)\n",
    "minception.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-Step Explanation\n",
    "1.  **ConvModule:** This wrapper standardizes the sequence `Conv -> Batch Norm -> ReLU`. Using Batch Normalization allows us to train deeper networks faster by normalizing activations.\n",
    "2.  **Inception-ResNet Block:** \n",
    "    * It branches into different paths (capturing features at different scales).\n",
    "    * It **Adds** the original input back to the output (`Add()`). This is the **Residual Connection**. It allows gradients to bypass the complex block if needed, solving the vanishing gradient problem.\n",
    "3.  **Reduction Block:** Instead of simple Max Pooling, we mix Max Pooling with strided convolutions. This preserves more information while downsampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ Section 3: Transfer Learning\n",
    "\n",
    "Instead of training from scratch, we can reuse a model trained on ImageNet (millions of images). We will use `InceptionResNetV2`.\n",
    "\n",
    "**Strategy:**\n",
    "1.  Load the model **without the top** (classification) layer.\n",
    "2.  Freeze the base layers (make them non-trainable) to preserve learned features.\n",
    "3.  Add our own classification head.\n",
    "4.  Train on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "\n",
    "def build_transfer_model(input_shape, n_classes):\n",
    "    # 1. Load Pretrained Model\n",
    "    # include_top=False means we drop the 1000-class ImageNet classifier\n",
    "    base_model = InceptionResNetV2(\n",
    "        include_top=False, \n",
    "        weights='imagenet', \n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    \n",
    "    # 2. Freeze the base model\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # 3. Add Custom Head\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    predictions = Dense(n_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    return model\n",
    "\n",
    "transfer_model = build_transfer_model((150, 150, 3), 10)\n",
    "\n",
    "# Note: InceptionResNetV2 expects inputs usually larger than 75x75.\n",
    "# We used (150, 150) for compatibility.\n",
    "transfer_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "\n",
    "print(f\"Total Params: {transfer_model.count_params():,}\")\n",
    "print(f\"Trainable Params: {transfer_model.count_params() - len(transfer_model.non_trainable_weights):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6️⃣ Section 4: Grad-CAM - Making the Model Confess\n",
    "\n",
    "Grad-CAM (Gradient-weighted Class Activation Mapping) allows us to visualize which parts of an image led the model to a specific decision. \n",
    "\n",
    "**Logic:** We take the gradients of the predicted class score with respect to the feature maps of the *last convolutional layer*. If a specific feature map location has a high gradient, it means that location strongly influenced the final score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # 1. Create a model that maps the input image to the activations\n",
    "    # of the last conv layer as well as the output predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # 2. Compute the Gradient\n",
    "    with tf.GradientTape() as tape:\n",
    "        last_conv_layer_output, preds = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(preds[0])\n",
    "        class_channel = preds[:, pred_index]\n",
    "\n",
    "    # This is the gradient of the output neuron (top predicted or chosen) \n",
    "    # with regard to the output feature map of the last conv layer\n",
    "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
    "\n",
    "    # 3. Vector weight computation (Gap)\n",
    "    # We pool the gradients over the height and width axes\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # 4. Multiply each channel in the feature map array\n",
    "    # by \"how important this channel is\" regarding the top predicted class\n",
    "    last_conv_layer_output = last_conv_layer_output[0]\n",
    "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # 5. Normalize the heatmap\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "# Test Grad-CAM with the Transfer Learning model\n",
    "# We need to find the last conv layer name. In InceptionResNetV2, it's typically 'conv_7b'\n",
    "last_conv_layer_name = 'conv_7b'\n",
    "\n",
    "# Create a dummy image for demonstration\n",
    "img_array = np.random.rand(1, 150, 150, 3).astype('float32')\n",
    "\n",
    "# Note: This will generate a noise heatmap because the model is untrained random weights\n",
    "# or frozen imagenet weights on random noise.\n",
    "# In a real scenario, you pass a real image.\n",
    "heatmap = make_gradcam_heatmap(img_array, transfer_model.layers[0], last_conv_layer_name)\n",
    "\n",
    "plt.matshow(heatmap)\n",
    "plt.title(\"Grad-CAM Heatmap\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7️⃣ Chapter Summary\n",
    "\n",
    "* **Fighting Overfitting:** We can significantly improve generalization using Data Augmentation (varying inputs), Dropout (randomly disabling neurons), and Early Stopping (stopping when validation loss plateaus).\n",
    "* **Minception:** We built a custom architecture inspired by Inception-ResNet. It uses **Batch Normalization** to stabilize training and **Residual Connections** to allow gradients to flow easily through deep networks.\n",
    "* **Transfer Learning:** We learned that we don't always need to train from scratch. We can take a massive model like InceptionResNetV2, freeze its learned features, and only train a small classifier on top to get state-of-the-art results on small datasets.\n",
    "* **Grad-CAM:** We opened the \"Black Box\" of CNNs. By calculating gradients of the output class w.r.t the last convolutional layer, we generated heatmaps showing exactly where the model is looking."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
