{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4: Dipping Toes in Deep Learning\n",
    "\n",
    "## 1️⃣ Chapter Overview\n",
    "\n",
    "In the previous chapters, we learned about the building blocks (Tensors, Variables) and the tools (Keras, tf.data) of TensorFlow. Now, we finally put them to use to build actual Deep Learning models.\n",
    "\n",
    "This chapter introduces the three fundamental pillars of deep learning architectures, applying each to a specific real-world problem type:\n",
    "\n",
    "1.  **Fully Connected Networks (FCNs):** We will build an **Autoencoder** to restore/denoise corrupted images (Unsupervised Learning).\n",
    "2.  **Convolutional Neural Networks (CNNs):** We will build a **Classifier** to identify objects in images using the CIFAR-10 dataset (Computer Vision).\n",
    "3.  **Recurrent Neural Networks (RNNs):** We will build a **Forecaster** to predict future CO2 levels based on historical time-series data (Sequence Modeling).\n",
    "\n",
    "**Practical Skills:**\n",
    "* Image restoration/denoising.\n",
    "* Handling multi-dimensional image data for CNNs.\n",
    "* Preprocessing time-series data (windowing, differencing) for RNNs.\n",
    "* Implementing `SimpleRNN`, `Conv2D`, and `Dense` layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2️⃣ Section 1: Fully Connected Networks (Autoencoders)\n",
    "\n",
    "### 2.1 Theoretical Explanation\n",
    "\n",
    "**What is an Autoencoder?**\n",
    "An Autoencoder is a type of neural network trained to copy its input to its output. It usually consists of two parts:\n",
    "1.  **Encoder:** Compresses the input $x$ into a lower-dimensional latent representation (code) $h$. \n",
    "    $$ h = f(x) $$\n",
    "2.  **Decoder:** Reconstructs the input $x'$ from the latent representation $h$.\n",
    "    $$ x' = g(h) $$\n",
    "\n",
    "**Why use it?**\n",
    "If the network is forced to prioritize which information to keep (by creating a bottleneck), it learns useful features about the data. Here, we use a **Denoising Autoencoder**. We feed it a *corrupted* image and force it to predict the *clean* original image. This forces the model to learn the underlying structure of the visual data to fill in the missing pieces.\n",
    "\n",
    "### 2.2 Data Preparation (MNIST)\n",
    "We will use the MNIST handwritten digits dataset. We will artificially corrupt the images by applying a random mask (setting pixels to black)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Load Data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 2. Preprocessing\n",
    "# We normalize inputs to [-1, 1] because we will use 'tanh' activation in the last layer.\n",
    "# Formula: (x - 127.5) / 127.5 approx equal to (x - 128) / 128\n",
    "x_train = (x_train.astype('float32') - 127.5) / 127.5\n",
    "x_test = (x_test.astype('float32') - 127.5) / 127.5\n",
    "\n",
    "# Flatten the images (28x28 -> 784) for the Fully Connected Network\n",
    "x_train = x_train.reshape((-1, 784))\n",
    "x_test = x_test.reshape((-1, 784))\n",
    "\n",
    "# 3. Corrupting Data Function\n",
    "def generate_masked_inputs(x, p=0.5, seed=42):\n",
    "    \"\"\"\n",
    "    Randomly sets pixels to 0 (black) with probability p.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    mask = np.random.binomial(n=1, p=p, size=x.shape).astype('float32')\n",
    "    return x * mask\n",
    "\n",
    "# Generate corrupted training data\n",
    "x_train_masked = generate_masked_inputs(x_train)\n",
    "x_test_masked = generate_masked_inputs(x_test)\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(x_train[0].reshape(28,28), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Corrupted (Input to Model)\")\n",
    "plt.imshow(x_train_masked[0].reshape(28,28), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Implementing the Autoencoder\n",
    "We will build a simple stack of Dense layers. The architecture is hourglass-shaped:\n",
    "Input (784) -> 64 -> 32 (Bottleneck) -> 64 -> Output (784)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the model\n",
    "autoencoder = Sequential([\n",
    "    # Encoder\n",
    "    Dense(64, activation='relu', input_shape=(784,)),\n",
    "    Dense(32, activation='relu'),\n",
    "    \n",
    "    # Decoder\n",
    "    Dense(64, activation='relu'),\n",
    "    # Output layer: tanh produces values in [-1, 1], matching our normalization\n",
    "    Dense(784, activation='tanh') \n",
    "])\n",
    "\n",
    "autoencoder.compile(loss='mse', optimizer='adam')\n",
    "autoencoder.summary()\n",
    "\n",
    "# Train the model\n",
    "# Input: Masked Images, Target: Original Images\n",
    "history = autoencoder.fit(x_train_masked, x_train, \n",
    "                          batch_size=64, \n",
    "                          epochs=10,\n",
    "                          validation_split=0.1,\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Evaluation\n",
    "Let's see how well our model restores unseen corrupted images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "restored_imgs = autoencoder.predict(x_test_masked)\n",
    "\n",
    "# Visualization\n",
    "n = 5\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i in range(n):\n",
    "    # Corrupted\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test_masked[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Corrupted\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    # Restored\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(restored_imgs[i].reshape(28, 28), cmap='gray')\n",
    "    plt.title(\"Restored\")\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3️⃣ Section 2: Convolutional Neural Networks (CNNs)\n",
    "\n",
    "### 3.1 Theoretical Explanation\n",
    "Fully connected networks destroy spatial information by flattening images. **CNNs** preserve the grid structure of images (height, width, channels).\n",
    "\n",
    "**Key Components:**\n",
    "1.  **Convolution:** Slides a small filter (kernel) over the image to detect local patterns (edges, textures).\n",
    "2.  **Pooling:** Downsamples the image (e.g., Max Pooling) to reduce dimensionality and provide translation invariance.\n",
    "\n",
    "**Dimensionality Arithmetic:**\n",
    "If input is $W$, filter size is $K$, padding is $P$, and stride is $S$, output size is:\n",
    "$$ \\frac{W - K + 2P}{S} + 1 $$\n",
    "\n",
    "### 3.2 Data Preparation (CIFAR-10)\n",
    "We use CIFAR-10, a dataset of 60,000 color images (32x32) in 10 classes (airplane, car, bird, cat, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load CIFAR-10 using TFDS\n",
    "data, info = tfds.load(\"cifar10\", with_info=True, as_supervised=True)\n",
    "train_data = data['train']\n",
    "test_data = data['test']\n",
    "\n",
    "def format_image(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    label = tf.one_hot(label, depth=10)\n",
    "    return image, label\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "train_ds = train_data.map(format_image).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_data.map(format_image).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"Image Shape:\", info.features['image'].shape)\n",
    "print(\"Num Classes:\", info.features['label'].num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Implementing the CNN\n",
    "We use `Conv2D` layers followed by `MaxPool2D`. \n",
    "\n",
    "**Note on Padding:** We use `padding='same'` to keep dimensions consistent after convolution, relying on Pooling to reduce the size. If we used `padding='valid'`, the size would shrink at every convolution, potentially causing \"Negative Dimension\" errors in deeper networks if the image becomes too small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten\n",
    "\n",
    "cnn = Sequential([\n",
    "    # Layer 1: Conv -> MaxPool\n",
    "    # Input: 32x32x3 -> Output: 32x32x16 (same padding) -> 16x16x16 (pooling)\n",
    "    Conv2D(16, (3,3), activation='relu', padding='same', input_shape=(32,32,3)),\n",
    "    MaxPool2D((2,2)),\n",
    "    \n",
    "    # Layer 2: Conv -> MaxPool\n",
    "    # Input: 16x16x16 -> Output: 16x16x32 -> 8x8x32\n",
    "    Conv2D(32, (3,3), activation='relu', padding='same'),\n",
    "    MaxPool2D((2,2)),\n",
    "    \n",
    "    # Layer 3: Conv (No pooling)\n",
    "    # Input: 8x8x32 -> Output: 8x8x64\n",
    "    Conv2D(64, (3,3), activation='relu', padding='same'),\n",
    "    \n",
    "    # Flatten for dense layers\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(10, activation='softmax') # 10 classes\n",
    "])\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "cnn.summary()\n",
    "\n",
    "# Train\n",
    "history_cnn = cnn.fit(train_ds, epochs=10, validation_data=test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4️⃣ Section 3: Recurrent Neural Networks (RNNs)\n",
    "\n",
    "### 4.1 Theoretical Explanation\n",
    "Standard networks assume inputs are independent (I.I.D). Time-series data (stock prices, weather) violates this; today's temperature depends on yesterday's.\n",
    "\n",
    "**RNNs** handle this by maintaining a **State (Memory)**. As they process a sequence, the output depends on both the current input $x_t$ and the previous state $h_{t-1}$.\n",
    "\n",
    "### 4.2 Data Preparation (CO2 Concentration)\n",
    "We will download a dataset of atmospheric CO2 concentrations and try to predict the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# 1. Download Data\n",
    "url = \"https://datahub.io/core/co2-ppm/r/co2-mm-gl.csv\"\n",
    "file_path = \"co2-mm-gl.csv\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    r = requests.get(url)\n",
    "    with open(file_path, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "data = pd.read_csv(file_path)\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data = data.set_index('Date')\n",
    "\n",
    "# 2. Preprocessing (Detrending)\n",
    "# The raw CO2 values constantly increase. This trend makes it hard for ML models.\n",
    "# We convert values to 'Differences': Value(t) - Value(t-1).\n",
    "# This makes the data stationary (range approx -2.0 to 1.5).\n",
    "data['Average Diff'] = data['Average'] - data['Average'].shift(1)\n",
    "data = data.dropna()\n",
    "\n",
    "# Visualization\n",
    "data['Average Diff'].plot(figsize=(10, 5), title=\"CO2 Monthly Differences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Windowing the Data\n",
    "RNNs need sequences as input. We cannot feed a single number to predict the next. \n",
    "\n",
    "**Strategy:**\n",
    "We take a window of past `N` values (e.g., 12 months) to predict the `N+1`th value.\n",
    "* Input shape: `(Batch_Size, Time_Steps, Features)`\n",
    "* Time Steps = 12\n",
    "* Features = 1 (just the CO2 value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(series, n_seq):\n",
    "    x, y = [], []\n",
    "    values = series.values\n",
    "    for i in range(len(values) - n_seq):\n",
    "        # Inputs: i to i+n_seq\n",
    "        x.append(values[i : i+n_seq])\n",
    "        # Target: i+n_seq (the next value)\n",
    "        y.append(values[i+n_seq])\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "N_SEQ = 12 # Look back 1 year\n",
    "x_rnn, y_rnn = generate_data(data['Average Diff'], N_SEQ)\n",
    "\n",
    "# Reshape for RNN: [Samples, Time_Steps, Features]\n",
    "x_rnn = x_rnn.reshape(-1, N_SEQ, 1)\n",
    "y_rnn = y_rnn.reshape(-1, 1)\n",
    "\n",
    "print(\"RNN Input Shape:\", x_rnn.shape)\n",
    "print(\"RNN Target Shape:\", y_rnn.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Implementing the RNN\n",
    "We use `SimpleRNN`. Note that this layer is computationally simpler than LSTM or GRU but suffers from the vanishing gradient problem for very long sequences. For 12 steps, it works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "rnn_model = Sequential([\n",
    "    # SimpleRNN layer\n",
    "    SimpleRNN(64, activation='relu', input_shape=(N_SEQ, 1)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1) # Regression output (predicting a continuous value)\n",
    "])\n",
    "\n",
    "rnn_model.compile(loss='mse', optimizer='adam')\n",
    "rnn_model.summary()\n",
    "\n",
    "# Train\n",
    "history_rnn = rnn_model.fit(x_rnn, y_rnn, epochs=20, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Forecasting the Future\n",
    "We can now use the model to predict CO2 levels. Note that the model predicts the *difference*. To get the actual value, we must add the predicted difference to the previous month's actual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's forecast the last 12 months known data to verify\n",
    "last_sequence = x_rnn[-1:]\n",
    "predicted_diff = rnn_model.predict(last_sequence)\n",
    "\n",
    "actual_last_val = data['Average'].iloc[-2] # The value before the one we predict\n",
    "predicted_val = actual_last_val + predicted_diff[0][0]\n",
    "\n",
    "print(f\"Predicted Diff: {predicted_diff[0][0]:.4f}\")\n",
    "print(f\"Predicted Absolute Value: {predicted_val:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5️⃣ Chapter Summary\n",
    "\n",
    "In this chapter, we implemented the \"Big Three\" architectures of deep learning:\n",
    "\n",
    "* **Fully Connected Networks (Autoencoders):**\n",
    "    * Used `Dense` layers.\n",
    "    * Learned to map Inputs $\\to$ Latent Code $\\to$ Inputs.\n",
    "    * Successfully removed noise from images.\n",
    "* **Convolutional Neural Networks (CNNs):**\n",
    "    * Used `Conv2D` and `MaxPool2D`.\n",
    "    * Learned spatial hierarchies in image data (Edges $\\to$ Shapes $\\to$ Objects).\n",
    "    * Achieved classification on CIFAR-10.\n",
    "* **Recurrent Neural Networks (RNNs):**\n",
    "    * Used `SimpleRNN`.\n",
    "    * Processed data sequentially, maintaining a memory of the past.\n",
    "    * Learned to forecast time-series trends."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
